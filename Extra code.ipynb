{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to be used\n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation as approx\n",
    "from networkx.algorithms import community\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ndlib.models.epidemics as ep\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import random\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import community\n",
    "# from time import sleep\n",
    "from igraph import *\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from networkx.algorithms import *\n",
    "\n",
    "\n",
    "# G = nx.erdos_renyi_graph(200, 0.1, directed = True)\n",
    "# print(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75888 508837\n",
    "# G = nx.read_edgelist(\"Wiki-Vote.txt\", create_using=nx.DiGraph(), nodetype=int)\n",
    "G1 = nx.read_edgelist(\"Wiki-Vote.txt\", create_using=nx.Graph(), nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.read_edgelist(\"facebook_combined.txt\", create_using=nx.Graph(), nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,v in G.edges():\n",
    "    G[u][v]['weight'] = 1/G.in_degree(v)\n",
    "G.get_edge_data(30,1412)\n",
    "# G.in_degree(1412)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = nx.community.louvain_communities(G)\n",
    "# print(lc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = list(nx.community.greedy_modularity_communities(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_community_size = min(len(community) for community in communities)\n",
    "\n",
    "# min_community_size = min(len(community) for community in lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_community_nodes = set(node for community in communities\n",
    "                            if len(community) == min_community_size\n",
    "                            for node in community)\n",
    "\n",
    "# small_community_nodes = set(node for community in lc\n",
    "#                             if len(lc) == min_community_size\n",
    "#                             for node in community)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(small_community_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree_node = max(small_community_nodes, key=G.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = set([max_degree_node])\n",
    "while True:\n",
    "    nodes = set(G)\n",
    "    nodes -= seeds\n",
    "    if not nodes:\n",
    "        break\n",
    "    node_scores = [(node, min([len(set(G.neighbors(n))) for n in seeds | set([node])]))\n",
    "                   for node in nodes]\n",
    "    node_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    if node_scores[0][1] == node_scores[-1][1]:\n",
    "        break\n",
    "    seeds.add(node_scores[0][0])\n",
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2565: 10.0, 1549: 4.5, 15: 2.6666666666666665, 72: 1.75, 737: 1.2000000000000002, 1166: 0.8333333333333333, 5079: 0.5714285714285714, 2328: 0.375, 2237: 0.2222222222222222, 28: 0.1}\n"
     ]
    }
   ],
   "source": [
    "bc = nx.betweenness_centrality(G)\n",
    "sorted_nodes = sorted(bc.items(), key=lambda item: item[1], reverse=True)\n",
    "num = 10\n",
    "fairness_allocation = {}\n",
    "for i, (node, bc_value) in enumerate(sorted_nodes):\n",
    "    allocation = (1/(i+1)) * (num - len(fairness_allocation))\n",
    "    fairness_allocation[node] = allocation\n",
    "    if len(fairness_allocation) == num:\n",
    "        break\n",
    "print(fairness_allocation)\n",
    "keyslist = list(fairness_allocation.keys())\n",
    "print(keyslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undir_betweenness = nx.betweenness_centrality(G1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding seeds using louvain communities and using the top node from each community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import community\n",
    "partition = community.best_partition(G_undir)\n",
    "\n",
    "community_sizes = {}\n",
    "for node, community_id in partition.items():\n",
    "    community_sizes[community_id] = community_sizes.get(community_id, 0) + 1\n",
    "\n",
    "# compute the average size of a communtiy\n",
    "avg_community_size = sum(community_sizes.values()) / len(community_sizes)\n",
    "\n",
    "# sort the communitities by size in descending order\n",
    "sorted_communities = sorted(community_sizes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# initialie list of seeds nodes\n",
    "seeds =[]\n",
    "\n",
    "# Iterate over the communities and add the top nodes to the seeds list\n",
    "for community_id, size in sorted_communities:\n",
    "    nodes = [node for node, c_id in partition.items() if c_id == community_id]\n",
    "    nodes_sorted = sorted(nodes, key=lambda n: G_undir.degree(n), reverse=True)\n",
    "    community_seed_count = int(round(size / avg_community_size))\n",
    "    seeds += nodes_sorted[:community_seed_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 1151, 1608, 789, 993, 1297, 311, 173, 6, 766, 457, 2688, 3456, 15, 5079, 1133, 2972, 1549, 1166, 3352, 2485, 2328, 2871, 2651, 2237, 2565, 1374, 5524, 4037, 737, 5802, 2658]\n"
     ]
    }
   ],
   "source": [
    "print(seeds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use louvain communities with equality fairness and betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7115\n"
     ]
    }
   ],
   "source": [
    "import community\n",
    "\n",
    "# Partition into communities\n",
    "partition = community.best_partition(G1)\n",
    "print(len(partition))\n",
    "# betweenness_centralities = {}\n",
    "closeness_centralities = {}\n",
    "degree_centralities = {}\n",
    "for community_id in set(partition.values()):\n",
    "    community_nodes = [n for n in partition.keys() if partition[n] == community_id]\n",
    "    community_subgraph = G1.subgraph(community_nodes)\n",
    "    # betweenness_centralities[community_id] = nx.betweenness_centrality(community_subgraph)\n",
    "    # degree_centralities[community_id] = nx.degree_centrality(community_subgraph)\n",
    "    closeness_centralities[community_id] = nx.closeness_centrality(community_subgraph)\n",
    "\n",
    "# Calculate fairness metric\n",
    "fairness_metrics = {}\n",
    "for community_id in set(partition.values()):\n",
    "    # fairness = max(betweenness_centralities[community_id].values()) - min(betweenness_centralities[community_id].values())\n",
    "    # fairness = max(degree_centralities[community_id].values()) - min(degree_centralities[community_id].values())\n",
    "    fairness = max(closeness_centralities[community_id].values()) - min(closeness_centralities[community_id].values())                                                                        \n",
    "    fairness_metrics[community_id] = fairness\n",
    "    \n",
    "# Calculate seeds from each community\n",
    "seeds = []\n",
    "min_fairness_community = min(fairness_metrics, key=fairness_metrics.get)\n",
    "\n",
    "for community_id in set(partition.values()):\n",
    "    community_nodes = [n for n in partition.keys() if partition[n] == community_id]\n",
    "    community_subgraph = G1.subgraph(community_nodes)\n",
    "\n",
    "    if community_id == min_fairness_community:\n",
    "        # node = max(betweenness_centralities[community_id], key=betweenness_centralities[community_id].get)\n",
    "        # node = max(degree_centralities[community_id], key=degree_centralities[community_id].get)\n",
    "        node = max(closeness_centralities[community_id], key=closeness_centralities[community_id].get)\n",
    "\n",
    "    else:\n",
    "        # nodes_sorted = sorted(betweenness_centralities[community_id].items(), key=lambda x: x[1], reverse=True)\n",
    "        # nodes_sorted = sorted(degree_centralities[community_id].items(), key=lambda x: x[1], reverse=True)\n",
    "        nodes_sorted = sorted(closeness_centralities[community_id].items(), key=lambda x: x[1], reverse=True)\n",
    "        node = nodes_sorted[0][0]\n",
    "\n",
    "    seeds.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary has 31 distinct values.\n"
     ]
    }
   ],
   "source": [
    "num_distinct_values = len(set(partition.values()))\n",
    "\n",
    "print(\"The dictionary has\", num_distinct_values, \"distinct values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 2565, 5524, 1166, 15, 6691, 2304, 5231, 3194, 3244, 8076, 4168, 4540, 4544, 5413, 5678, 5766, 5970, 6025, 6089, 6100, 6258, 6266, 7033, 7190, 7194, 7467, 7494, 7972, 7981, 8014]\n"
     ]
    }
   ],
   "source": [
    "print(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code can be used with the previous two cell blocks to calculate the influence count. \n",
    "# It combines the method of calculating the spread using spreading model as defined in the NDlib package, witht the different heuristic approaches.\n",
    "for index in range(4):\n",
    "    # model = ep.IndependentCascadesModel(G1)\n",
    "    model = ep.ThresholdModel(G1)\n",
    "    cfg = mc.Configuration()\n",
    "    # cfg.add_model_parameter('beta', 0.01)\n",
    "    # cfg.add_model_parameter('lambda', 0.005)\n",
    "    infected_nodes = seeds\n",
    "    cfg.add_model_initial_configuration(\"Infected\", infected_nodes)\n",
    "    # cfg.add_model_parameter(\"fraction_infected\", 0.05)\n",
    "    model.set_initial_status(cfg)\n",
    "    # threshold = 0.2\n",
    "    # for e in G1.edges():\n",
    "    #     cfg.add_edge_configuration(\"threshold\", e, random.uniform(0,1))\n",
    "    for n in G1.nodes():\n",
    "        cfg.add_node_configuration(\"threshold\", n, random.uniform(0, 1))\n",
    "\n",
    "    # iterations = model.iteration_bunch(500, True, True)\n",
    "    # trends = model.build_trends(iterations)\n",
    "    # viz = DiffusionTrend(model, trends)\n",
    "    # p = viz.plot(width=800, height=800)\n",
    "    # show(p)\n",
    "    list = []\n",
    "    for i in range(0,1000):\n",
    "        iterations = model.iteration_bunch(1)\n",
    "\n",
    "        dict = iterations[0]\n",
    "        for i in dict:\n",
    "            k = (i,dict[i])\n",
    "            list.append(k)\n",
    "    list2 = []\n",
    "    for i in range(len(list)):\n",
    "        if list[i][0] == 'status':\n",
    "            list2.append(list[i][1])\n",
    "    list4 = []\n",
    "    for t in range(len(list2)):\n",
    "        for f in list2[t]:\n",
    "            if list2[t][f] == 1:\n",
    "                list4.append(f)\n",
    "    print(\"================================\")\n",
    "    print(f\"Results for iteration {index+1}:\")\n",
    "    print(\"Total nodes infected: \", len(list4), \"out of\", len(G1.nodes()))\n",
    "    print(\"Percentage of total infected nodes with current seed set: \", (len(list4)/len(G1.nodes()))*100, \"%\")\n",
    "    print(\"================================\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nx_comm.louvain_communities(g, seed = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = nx.read_edgelist(\"Wiki-Vote.txt\", create_using=nx.DiGraph(), nodetype= int)\n",
    "model = ep.IndependentCascadesModel(G)\n",
    "config = mc.Configuration()\n",
    "infected_nodes = result\n",
    "config.add_model_initial_configuration(\"Infected\", infected_nodes)\n",
    "threshold = 0.1\n",
    "for e in G.edges():\n",
    "    config.add_edge_configuration(\"threshold\", e, random.uniform(0,1))\n",
    "model.set_initial_status(config)\n",
    "iterations = model.iteration_bunch(500,False,True)\n",
    "trends = model.build_trends(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show\n",
    "from ndlib.viz.bokeh.DiffusionTrend import DiffusionTrend\n",
    "\n",
    "viz = DiffusionTrend(model, trends)\n",
    "p = viz.plot(width=600, height=600)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4167, 4168, 4540, 4541, 2565, 766, 2237, 2688, 2328, 3352, 2398, 2485, 1133, 2871, 2654, 4191, 8293, 2535, 2651, 68, 4261, 1305, 3028, 988, 825, 4247, 2790, 2660]\n"
     ]
    }
   ],
   "source": [
    "import community\n",
    "import itertools\n",
    "\n",
    "new_partition = community.best_partition(G1)\n",
    "betweenness = nx.betweenness_centrality(G1)\n",
    "\n",
    "min_betweenness = {}\n",
    "for node, community_id in new_partition.items():\n",
    "    if community_id not in min_betweenness or betweenness[node] < min_betweenness[community_id]:\n",
    "        min_betweenness[community_id] = betweenness[node]\n",
    "\n",
    "candidate_seeds = []\n",
    "\n",
    "for community1, community2 in itertools.combinations(set(new_partition.values()),2):\n",
    "    max_betweenness = -1\n",
    "    max_node = None\n",
    "    for node in G1.nodes():\n",
    "        if new_partition[node] == community1 and node not in candidate_seeds:\n",
    "            if betweenness[node] > max_betweenness:\n",
    "                max_betweenness = betweenness[node]\n",
    "                max_node = node\n",
    "    \n",
    "    if max_betweenness >= min_betweenness[community2]:\n",
    "        candidate_seeds.append(max_node)\n",
    "    if len(candidate_seeds) == 28:\n",
    "        break\n",
    "\n",
    "print(candidate_seeds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
